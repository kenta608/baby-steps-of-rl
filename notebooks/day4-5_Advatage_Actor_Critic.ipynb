{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37906ed5-089e-4212-b66b-fdbc365edc33",
   "metadata": {},
   "source": [
    "# 4-5 Advantage Actor Critic (A2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa740649-3e15-451d-a825-31e2a39c2ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-24 14:45:06.165409: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-11-24 14:45:06.206828: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz\n",
      "2022-11-24 14:45:06.211349: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560a577eef60 executing computations on platform Host. Devices:\n",
      "2022-11-24 14:45:06.211374: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
      "2022-11-24 14:45:06.213291: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
      "2022-11-24 14:45:06.618855: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560a59b3d570 executing computations on platform CUDA. Devices:\n",
      "2022-11-24 14:45:06.618888: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2022-11-24 14:45:06.618894: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2022-11-24 14:45:06.618897: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2022-11-24 14:45:06.618900: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2022-11-24 14:45:06.620728: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:3d:00.0\n",
      "2022-11-24 14:45:06.621627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:3e:00.0\n",
      "2022-11-24 14:45:06.622684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:88:00.0\n",
      "2022-11-24 14:45:06.623691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: \n",
      "name: Tesla V100-PCIE-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.38\n",
      "pciBusID: 0000:89:00.0\n",
      "2022-11-24 14:45:06.623810: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-11-24 14:45:06.623858: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-11-24 14:45:06.623899: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-11-24 14:45:06.623940: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-11-24 14:45:06.623980: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-11-24 14:45:06.624020: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:\n",
      "2022-11-24 14:45:06.627773: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-11-24 14:45:06.627790: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\n",
      "2022-11-24 14:45:06.627819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-11-24 14:45:06.627825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 1 2 3 \n",
      "2022-11-24 14:45:06.627829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N Y Y Y \n",
      "2022-11-24 14:45:06.627832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 1:   Y N Y Y \n",
      "2022-11-24 14:45:06.627834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 2:   Y Y N Y \n",
      "2022-11-24 14:45:06.627837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 3:   Y Y Y N \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 5847636411644546285,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 17314364496554502713\n",
       " physical_device_desc: \"device: XLA_CPU device\",\n",
       " name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 13801906824802298310\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:1\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 11070226894451675079\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:2\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 10655573977658148663\n",
       " physical_device_desc: \"device: XLA_GPU device\",\n",
       " name: \"/device:XLA_GPU:3\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 3768294989851588831\n",
       " physical_device_desc: \"device: XLA_GPU device\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TensorFlowがGPUを認識しているか確認\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b79a328-c2e0-4f79-9105-111cce2af506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "couldn't import doomish\n",
      "Couldn't import doom\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras as K\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython import display\n",
    "import gym\n",
    "import gym_ple\n",
    "import sys\n",
    "sys.path.append(\"../FN\")\n",
    "from fn_framework import FNAgent, Trainer, Observer\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4d1d31-a63c-4583-8fe6-67ce4609c773",
   "metadata": {},
   "source": [
    "code 4-24 agent定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8abe7e82-7b61-402b-834f-b63d8b2fdf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCriticAgent(FNAgent):\n",
    "\n",
    "    def __init__(self, actions):\n",
    "        # ActorCriticAgent uses self policy (doesn't use epsilon).\n",
    "        super().__init__(epsilon=0.0, actions=actions)\n",
    "        self._updater = None\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, env, model_path):\n",
    "        actions = list(range(env.action_space.n))\n",
    "        agent = cls(actions)\n",
    "        agent.model = K.models.load_model(model_path, custom_objects={\n",
    "                        \"SampleLayer\": SampleLayer})\n",
    "        agent.initialized = True\n",
    "        return agent\n",
    "\n",
    "    def initialize(self, experiences, optimizer):\n",
    "        feature_shape = experiences[0].s.shape\n",
    "        self.make_model(feature_shape)\n",
    "        self.set_updater(optimizer)\n",
    "        self.initialized = True\n",
    "        print(\"Done initialization. From now, begin training!\")\n",
    "\n",
    "    def make_model(self, feature_shape):\n",
    "        normal = K.initializers.glorot_normal()\n",
    "        model = K.Sequential()\n",
    "        model.add(K.layers.Conv2D(\n",
    "            32, kernel_size=8, strides=4, padding=\"same\",\n",
    "            input_shape=feature_shape,\n",
    "            kernel_initializer=normal, activation=\"relu\"))\n",
    "        model.add(K.layers.Conv2D(\n",
    "            64, kernel_size=4, strides=2, padding=\"same\",\n",
    "            kernel_initializer=normal, activation=\"relu\"))\n",
    "        model.add(K.layers.Conv2D(\n",
    "            64, kernel_size=3, strides=1, padding=\"same\",\n",
    "            kernel_initializer=normal, activation=\"relu\"))\n",
    "        model.add(K.layers.Flatten())\n",
    "        model.add(K.layers.Dense(256, kernel_initializer=normal,\n",
    "                                 activation=\"relu\"))\n",
    "        # -------- ここまではactorもcriticも共用 --------\n",
    "        # actor layer: Q(s, a)を出力し、後述のsample layerで行動を価値に基づいてsampling\n",
    "        actor_layer = K.layers.Dense(len(self.actions),\n",
    "                                     kernel_initializer=normal)\n",
    "        action_evals = actor_layer(model.output)\n",
    "        actions = SampleLayer()(action_evals)\n",
    "        # critic layer: 状態のみの価値 V(s) を出力する\n",
    "        critic_layer = K.layers.Dense(1, kernel_initializer=normal)\n",
    "        values = critic_layer(model.output)\n",
    "\n",
    "        self.model = K.Model(inputs=model.input,\n",
    "                             outputs=[actions, action_evals, values])\n",
    "\n",
    "    def set_updater(self, optimizer,\n",
    "                    value_loss_weight=1.0, entropy_weight=0.1):\n",
    "        actions = tf.compat.v1.placeholder(shape=(None), dtype=\"int32\")\n",
    "        values = tf.compat.v1.placeholder(shape=(None), dtype=\"float32\")\n",
    "\n",
    "        _, action_evals, estimateds = self.model.output\n",
    "        \n",
    "        # -log pi (a|s) \n",
    "        neg_logs = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                        logits=action_evals, labels=actions)\n",
    "        # tf.stop_gradient: Prevent policy_loss influences critic_layer.\n",
    "        advantages = values - tf.stop_gradient(estimateds)\n",
    "\n",
    "        # policy loss -> actor layer側のloss\n",
    "        # value loss -> critic layer側のloss\n",
    "        policy_loss = tf.reduce_mean(neg_logs * advantages)\n",
    "        value_loss = tf.keras.losses.MeanSquaredError()(values, estimateds)\n",
    "        # 過学習を防ぐ措置\n",
    "        action_entropy = tf.reduce_mean(self.categorical_entropy(action_evals))\n",
    "\n",
    "        loss = policy_loss + value_loss_weight * value_loss\n",
    "        loss -= entropy_weight * action_entropy\n",
    "\n",
    "        updates = optimizer.get_updates(loss=loss,\n",
    "                                        params=self.model.trainable_weights)\n",
    "\n",
    "        self._updater = K.backend.function(\n",
    "                                        inputs=[self.model.input,\n",
    "                                                actions, values],\n",
    "                                        outputs=[loss,\n",
    "                                                 policy_loss,\n",
    "                                                 value_loss,\n",
    "                                                 tf.reduce_mean(neg_logs),\n",
    "                                                 tf.reduce_mean(advantages),\n",
    "                                                 action_entropy],\n",
    "                                        updates=updates)\n",
    "\n",
    "    def categorical_entropy(self, logits):\n",
    "        \"\"\"\n",
    "        From OpenAI baseline implementation.\n",
    "        https://github.com/openai/baselines/blob/master/baselines/common/distributions.py#L192\n",
    "        \"\"\"\n",
    "        a0 = logits - tf.reduce_max(logits, axis=-1, keepdims=True)\n",
    "        ea0 = tf.exp(a0)\n",
    "        z0 = tf.reduce_sum(ea0, axis=-1, keepdims=True)\n",
    "        p0 = ea0 / z0\n",
    "        return tf.reduce_sum(p0 * (tf.math.log(z0) - a0), axis=-1)\n",
    "\n",
    "    def policy(self, s):\n",
    "        \"\"\"モデルから行動を出力\"\"\"\n",
    "        if not self.initialized:\n",
    "            return np.random.randint(len(self.actions))\n",
    "        else:\n",
    "            action, action_evals, values = self.model.predict(np.array([s]))\n",
    "            return action[0]\n",
    "\n",
    "    def estimate(self, s):\n",
    "        \"\"\"モデルから状態価値V(s)を出力\"\"\"\n",
    "        action, action_evals, values = self.model.predict(np.array([s]))\n",
    "        return values[0][0]\n",
    "\n",
    "    def update(self, states, actions, rewards):\n",
    "        return self._updater([states, actions, rewards])\n",
    "    \n",
    "    # jupyter labで描画させるためにoverlap\n",
    "    def play(self, env, episode_count=1, render=True):\n",
    "        action_dic = {0: \"neutral\", 1: \"right\", 2: \"left\"}\n",
    "        for e in range(episode_count):\n",
    "            s = env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "            cnt = 0\n",
    "            get_num = 0\n",
    "            play_num = 1\n",
    "            while not done:\n",
    "                # 毎回レンダリングすると遅くなるので最初の50回は毎回レンダリングし、その後は50回おきにする\n",
    "                if render and (cnt <= 50):\n",
    "                    env.render()\n",
    "                elif render and (cnt % 50 == 0):\n",
    "                    env.render()\n",
    "                a = self.policy(s)\n",
    "                n_state, reward, done, info = env.step(a)\n",
    "                plt.title(f\"episode={e}, action={action_dic[a]}, done={done}, frame={cnt}\")\n",
    "                episode_reward += reward\n",
    "                s = n_state\n",
    "                cnt += 1\n",
    "            else:\n",
    "                print(\"Get reward {}.\".format(episode_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7bf01f-d60e-4849-b2c4-eb20270865cd",
   "metadata": {},
   "source": [
    "code 4-26 学習モデルから行動を選択する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc4a79bd-c2d9-40f6-9654-4b45bd01ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SampleLayer(K.layers.Layer):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.output_dim = 1  # sample one action from evaluations\n",
    "        super(SampleLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(SampleLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"Gaumbel Max Trick\n",
    "        サンプリングの際にノイズを乗せて、行動をバラつかせる\n",
    "        \"\"\"\n",
    "        noise = tf.random.uniform(tf.shape(x))\n",
    "        return tf.argmax(x - tf.math.log(-tf.math.log(noise)), axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0c22a-0e23-4f11-a9a6-cbec2fca9474",
   "metadata": {},
   "source": [
    "code 4-27 価値関数の実装でも行ったテスト用Agentの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925491e9-7a75-43b3-bca6-1b25824061ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCriticAgentTest(ActorCriticAgent):\n",
    "\n",
    "    def make_model(self, feature_shape):\n",
    "        normal = K.initializers.glorot_normal()\n",
    "        model = K.Sequential()\n",
    "        model.add(K.layers.Dense(10, input_shape=feature_shape,\n",
    "                                 kernel_initializer=normal, activation=\"relu\"))\n",
    "        model.add(K.layers.Dense(10, kernel_initializer=normal,\n",
    "                                 activation=\"relu\"))\n",
    "\n",
    "        actor_layer = K.layers.Dense(len(self.actions),\n",
    "                                     kernel_initializer=normal)\n",
    "\n",
    "        action_evals = actor_layer(model.output)\n",
    "        actions = SampleLayer()(action_evals)\n",
    "\n",
    "        critic_layer = K.layers.Dense(1, kernel_initializer=normal)\n",
    "        values = critic_layer(model.output)\n",
    "\n",
    "        self.model = K.Model(inputs=model.input,\n",
    "                             outputs=[actions, action_evals, values])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbaf418-e58a-42f7-975a-e3135d379673",
   "metadata": {},
   "source": [
    "code 4-28 observer定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a60b29-1915-4f0a-a964-565fd7f51f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CatcherObserver(Observer):\n",
    "\n",
    "    def __init__(self, env, width, height, frame_count):\n",
    "        super().__init__(env)\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.frame_count = frame_count\n",
    "        self._frames = deque(maxlen=frame_count)\n",
    "\n",
    "    def transform(self, state):\n",
    "        grayed = Image.fromarray(state).convert(\"L\")\n",
    "        resized = grayed.resize((self.width, self.height))\n",
    "        resized = np.array(resized).astype(\"float\")\n",
    "        normalized = resized / 255.0  # scale to 0~1\n",
    "        if len(self._frames) == 0:\n",
    "            for i in range(self.frame_count):\n",
    "                self._frames.append(normalized)\n",
    "        else:\n",
    "            self._frames.append(normalized)\n",
    "        feature = np.array(self._frames)\n",
    "        # Convert the feature shape (f, w, h) => (h, w, f).\n",
    "        feature = np.transpose(feature, (1, 2, 0))\n",
    "        return feature\n",
    "    \n",
    "    # jupyter labで描画させるためにoverlap\n",
    "    def render(self):\n",
    "        # self._env.render(mode=\"rgb_array\")\n",
    "        plt.imshow(self._env.render(mode=\"rgb_array\"))\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4fc991-a190-437a-ac29-bcd8f72ec1be",
   "metadata": {},
   "source": [
    "code 4-29 Trainer定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e88f3e18-1557-4c18-9e1a-33227c4507a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCriticTrainer(Trainer):\n",
    "\n",
    "    def __init__(self, buffer_size=256, batch_size=32,\n",
    "                 gamma=0.99, learning_rate=1e-3,\n",
    "                 report_interval=10, log_dir=\"\", file_name=\"\"):\n",
    "        super().__init__(buffer_size, batch_size, gamma,\n",
    "                         report_interval, log_dir)\n",
    "        self.file_name = file_name if file_name else \"a2c_agent.h5\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.losses = {}\n",
    "        self.rewards = []\n",
    "        self._max_reward = -10\n",
    "\n",
    "    def train(self, env, episode_count=900, initial_count=10,\n",
    "              test_mode=False, render=False, observe_interval=100):\n",
    "        actions = list(range(env.action_space.n))\n",
    "        if not test_mode:\n",
    "            agent = ActorCriticAgent(actions)\n",
    "        else:\n",
    "            agent = ActorCriticAgentTest(actions)\n",
    "            observe_interval = 0\n",
    "        self.training_episode = episode_count\n",
    "\n",
    "        self.train_loop(env, agent, episode_count, initial_count, render,\n",
    "                        observe_interval)\n",
    "        return agent\n",
    "\n",
    "    def episode_begin(self, episode, agent):\n",
    "        self.rewards = []\n",
    "\n",
    "    def step(self, episode, step_count, agent, experience):\n",
    "        self.rewards.append(experience.r)\n",
    "        if not agent.initialized:\n",
    "            if len(self.experiences) < self.buffer_size:\n",
    "                # Store experience until buffer_size (enough to initialize).\n",
    "                return False\n",
    "\n",
    "            optimizer = K.optimizers.Adam(lr=self.learning_rate,\n",
    "                                          clipnorm=5.0)\n",
    "            agent.initialize(self.experiences, optimizer)\n",
    "            self.logger.set_model(agent.model)\n",
    "            self.training = True\n",
    "            self.experiences.clear()\n",
    "        else:\n",
    "            if len(self.experiences) < self.batch_size:\n",
    "                # Store experience until batch_size (enough to update).\n",
    "                return False\n",
    "\n",
    "            batch = self.make_batch(agent)\n",
    "            # エピソードの終了を待たずに学習を行う\n",
    "            # 報酬が得られていない状態に関してはCritic(layer)の見積もりを使用する\n",
    "            loss, lp, lv, p_ng, p_ad, p_en = agent.update(*batch)\n",
    "            # Record latest metrics.\n",
    "            self.losses[\"loss/total\"] = loss\n",
    "            self.losses[\"loss/policy\"] = lp\n",
    "            self.losses[\"loss/value\"] = lv\n",
    "            self.losses[\"policy/neg_logs\"] = p_ng\n",
    "            self.losses[\"policy/advantage\"] = p_ad\n",
    "            self.losses[\"policy/entropy\"] = p_en\n",
    "            self.experiences.clear()\n",
    "\n",
    "    def make_batch(self, agent):\n",
    "        states = []\n",
    "        actions = []\n",
    "        values = []\n",
    "        experiences = list(self.experiences)\n",
    "        states = np.array([e.s for e in experiences])\n",
    "        actions = np.array([e.a for e in experiences])\n",
    "\n",
    "        # Calculate values.\n",
    "        # If the last experience isn't terminal (done) then estimates value.\n",
    "        last = experiences[-1]\n",
    "        # 価値の見積もりを行うかどうかの判定 (last.dでエピソードが終了しているのかどうかを判断)\n",
    "        future = last.r if last.d else agent.estimate(last.n_s)\n",
    "        for e in reversed(experiences):\n",
    "            value = e.r\n",
    "            if not e.d:\n",
    "                value += self.gamma * future\n",
    "            values.append(value)\n",
    "            future = value\n",
    "        values = np.array(list(reversed(values)))\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        values = scaler.fit_transform(values.reshape((-1, 1))).flatten()\n",
    "\n",
    "        return states, actions, values\n",
    "\n",
    "    def episode_end(self, episode, step_count, agent):\n",
    "        reward = sum(self.rewards)\n",
    "        self.reward_log.append(reward)\n",
    "\n",
    "        if agent.initialized:\n",
    "            self.logger.write(self.training_count, \"reward\", reward)\n",
    "            self.logger.write(self.training_count, \"reward_max\",\n",
    "                              max(self.rewards))\n",
    "\n",
    "            for k in self.losses:\n",
    "                self.logger.write(self.training_count, k, self.losses[k])\n",
    "\n",
    "            if reward > self._max_reward:\n",
    "                agent.save(self.logger.path_of(self.file_name))\n",
    "                self._max_reward = reward\n",
    "\n",
    "        if self.is_event(episode, self.report_interval):\n",
    "            recent_rewards = self.reward_log[-self.report_interval:]\n",
    "            self.logger.describe(\"reward\", recent_rewards, episode=episode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5baa7bd8-a866-4490-8c06-4ce3e586cedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(play, is_test):\n",
    "    file_name = \"a2c_agent.h5\" if not is_test else \"a2c_agent_test.h5\"\n",
    "    trainer = ActorCriticTrainer(file_name=file_name)\n",
    "    path = trainer.logger.path_of(trainer.file_name)\n",
    "    agent_class = ActorCriticAgent\n",
    "\n",
    "    if is_test:\n",
    "        print(\"Train on test mode\")\n",
    "        obs = gym.make(\"CartPole-v0\")\n",
    "        agent_class = ActorCriticAgentTest\n",
    "    else:\n",
    "        env = gym.make(\"Catcher-v0\")\n",
    "        obs = CatcherObserver(env, 80, 80, 4)\n",
    "        trainer.learning_rate = 7e-5\n",
    "\n",
    "    if play:\n",
    "        agent = agent_class.load(obs, path)\n",
    "        agent.play(obs, episode_count=1, render=True)\n",
    "    else:\n",
    "        trainer.train(obs, test_mode=is_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74fd405b-140d-4091-b981-901f872f97bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get reward 14.0.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"A2C Agent\")\n",
    "parser.add_argument(\"--play\", action=\"store_true\",\n",
    "                    help=\"play with trained model\")\n",
    "parser.add_argument(\"--test\", action=\"store_true\",\n",
    "                    help=\"train by test mode\")\n",
    "\n",
    "args = parser.parse_args(args=[\"--play\"])\n",
    "main(args.play, args.test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
